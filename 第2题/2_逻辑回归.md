# 逻辑回归

逻辑回归（Logistic Regression）是一种常用的统计和机器学习模型，尽管名字里有“回归”，它实际上是一种**分类**模型，主要用于解决**二分类问题**。简单来说，逻辑回归的目标是预测某个事件的发生概率，比如根据症状预测一个人是否会得病，或根据邮件内容预测一封邮件是否是垃圾邮件。

## 知识点

### 从线性回归到分类

逻辑回归的核心思想是：将线性回归的输出结果**映射**到一个**概率值**，即：我们希望预测一个事件发生的概率，而不是一个具体的数值。

如何做到这一点？我们用到一个**S形函数**，称为**Sigmoid函数**，它的形式如下：
$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$
其中，z 是线性回归的输出（即：$z = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + b$），Sigmoid 函数会将 z 转换成一个**0 到 1 之间的数值**，这个数值可以解释为某个事件发生的概率。

假设我们预测一个人是否会生病，逻辑回归模型可能输出 P=0.8，这表示模型认为这个人有 80% 的可能性会生病。

### 分类决策

当我们有了概率值后，我们还需要做出最终的决策，即将预测的概率值转化为具体的分类结果。在二分类问题中，常见的做法是使用一个**阈值**（通常是 0.5）：

- 如果预测的概率大于 0.5，则我们分类为“1”类（比如，预测为会生病）。
- 如果概率小于等于 0.5，则分类为“0”类（比如，预测为不会生病）。

### 损失函数：二元交叉熵

为了训练逻辑回归模型，我们需要定义一个损失函数来衡量模型预测与真实结果的差距。逻辑回归常用的损失函数是**二元交叉熵损失**，它的公式是：
$$
L = -\frac{1}{m} \sum_{i=1}^{m} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
$$
其中，$y_i$ 是第 $i$ 个样本的真实标签（0 或 1），$\hat{y}_i$ 是模型预测的概率值，m 是样本总数。通过优化这个损失函数，模型会调整权重 w 和偏置 b，使得预测结果更加准确。

## 题目

使用泰坦尼克号乘客生存数据集（https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv），完成以下任务：

1. **加载并预处理数据**：包括处理缺失值、类别变量编码，以及选择相关特征。
2. **数据标准化**：对训练集和测试集进行标准化处理。
3. **模型构建与训练**：使用逻辑回归模型对数据进行训练。
4. **模型评估**：通过准确率、混淆矩阵和 ROC 曲线评估模型性能。

代码提供了整体框架，请在了解整个流程的基础上完成 **填空 1、2 和 3**。